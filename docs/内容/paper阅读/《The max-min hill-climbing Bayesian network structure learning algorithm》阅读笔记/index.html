<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  
  <link rel="shortcut icon" href="../../../img/favicon.ico">
  <title>《The max-min hill-climbing Bayesian network structure learning algorithm》阅读笔记 - Huang Hao's Blog</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700" />

  <link rel="stylesheet" href="../../../css/theme.css" />
  <link rel="stylesheet" href="../../../css/theme_extra.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
  
  <script>
    // Current page data
    var mkdocs_page_name = "\u300aThe max-min hill-climbing Bayesian network structure learning algorithm\u300b\u9605\u8bfb\u7b14\u8bb0";
    var mkdocs_page_input_path = "\u5185\u5bb9\\paper\u9605\u8bfb\\\u300aThe max-min hill-climbing Bayesian network structure learning algorithm\u300b\u9605\u8bfb\u7b14\u8bb0.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../../../js/jquery-2.1.1.min.js" defer></script>
  <script src="../../../js/modernizr-2.8.3.min.js" defer></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
        <a href="../../.." class="icon icon-home"> Huang Hao's Blog</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../..">Huang Hao' Blog</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">内容</span></p>
                <ul class="current">
                    <li class="toctree-l1 current"><a class="reference internal current" href="#">Paper阅读</a>
    <ul class="current">
                <li class="toctree-l2"><a class="reference internal" href="../Bayesian%20network%20structure%20learning%20%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E9%97%AE%E9%A2%98/">Bayesian network structure learning: 最短路径问题</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../EM%20algorithm%20%E6%9C%9F%E6%9C%9B%E6%9C%80%E5%A4%A7%E7%AE%97%E6%B3%95/">EM algorithm 期望最大算法</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../K2%E7%AE%97%E6%B3%95%E3%80%8AA%20Bayesian%20Method%20for%20the%20Induction%20of%20Probabilistic%20Networks%20from%20Data%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">K2算法《A Bayesian Method for the Induction of Probabilistic Networks from Data》阅读笔记</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../Linear%20non-Gaussian%20Acyclic%20Model/">A Linear Non-Gaussian Acyclic Model for Causal Discovery</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../%E3%80%8AA%20Survey%20of%20Learning%20Causality%20with%20Data%20Problems%20and%20Methods%E3%80%8B/">《A Survey of Learning Causality with Data: Problems and Methods》阅读笔记</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../%E3%80%8AAtomistic%20Line%20Graph%20Neural%20Network%20for%20improved%20materials%20property%20predictions%E3%80%8B%20%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">《Atomistic Line Graph Neural Network for improved materials property predictions》 阅读笔记</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../%E3%80%8ACAUSAL%20DISCOVERY%20WITH%20REINFORCEMENT%20LEARNING%E3%80%8B%20%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">《CAUSAL DISCOVERY WITH REINFORCEMENT LEARNING》 读书笔记</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../%E3%80%8AExploiting%20Experts%E2%80%99%20Knowledge%20for%20Structure%20Learning%20of%20Bayesian%20Networks%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">《Exploiting Experts’ Knowledge for Structure Learning of Bayesian Networks》阅读笔记</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../%E3%80%8AImproved%20K2%20algorithm%20for%20Bayesian%20network%20structure%20learning%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">《Improved K2 algorithm for Bayesian network structure learning》阅读笔记</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../%E3%80%8ALearning%20to%20Optimize%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">《Learning to Optimize》阅读笔记</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../%E3%80%8ANEURAL%20COMBINATORIAL%20OPTIMIZATION%20WITH%20REINFORCEMENT%20LEARNING%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">《NEURAL COMBINATORIAL OPTIMIZATION WITH REINFORCEMENT LEARNING》读书笔记</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../%E3%80%8ANeural%20Machine%20Translation%20By%20Jointly%20Learning%20To%20Align%20And%20Translate%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">《Neural Machine Translation By Jointly Learning To Align And Translate》阅读笔记</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../%E3%80%8APC%20algorithm%E3%80%8B%E5%AD%A6%E4%B9%A0/">《PC algorithm》学习</a>
                </li>
                <li class="toctree-l2 current"><a class="reference internal current" href="./">《The max-min hill-climbing Bayesian network structure learning algorithm》阅读笔记</a>
    <ul class="current">
    <li class="toctree-l3"><a class="reference internal" href="#abstract">abstract</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#introduction">introduction</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#background">background</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#the-max-min-parents-and-children-algorithm-mmpc">the max min parents and children algorithm （MMPC算法）</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#_1">案例：</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#tests-of-conditional-independence-and-measures-of-association">Tests of conditional independence and measures of association</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#mmhc">MMHC</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#optimizing-the-computational-performance">optimizing the computational performance</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#empirical-evaluation">empirical evaluation</a>
    </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../%E3%80%8Aattention%20is%20all%20your%20need%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">《attention is all your need》阅读笔记</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../%E3%80%8Adetermining%20the%20direction%20of%20the%20local%20search%20in%20topological%20ordering%20space%20for%20Bayesian%20network%20structure%20learning%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94/">《determining the direction of the local search in topological ordering space for Bayesian network structure learning》阅读笔记</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../%E3%80%8AdirectLiGAM%E3%80%8B%E7%BB%93%E6%9E%84%E6%96%B9%E7%A8%8B%E6%A8%A1%E5%9E%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">《A Linear Non-Gaussian Acyclic Model for Causal Discovery》读书笔记</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../%E3%80%8Apointer%20networks%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">《pointer networks》阅读笔记</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90%EF%BC%9A%E4%B8%89%E6%AC%A1%E6%A0%B7%E6%9D%A1%E6%8F%92%E5%80%BC/">数值分析：三次样条插值</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../%E9%A2%91%E7%8E%87%E7%BB%9F%E8%AE%A1%E5%AD%A6VS%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BB%9F%E8%AE%A1%E5%AD%A6/">频率统计学VS贝叶斯统计学</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="#">《Neural Machine Translation By Jointly Learning To Align And Translate》阅读笔记.assets</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../%E3%80%8ANeural%20Machine%20Translation%20By%20Jointly%20Learning%20To%20Align%20And%20Translate%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0.assets/BIC%20%E8%AF%84%E5%88%86/">BIC 评分</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="#">《PC algorithm》学习.assets</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../%E3%80%8APC%20algorithm%E3%80%8B%E5%AD%A6%E4%B9%A0.assets/%E3%80%8AStructure%20Learning%20of%20Bayesian%20Networks%20by%20Genetic%20Algorithms%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">《Structure Learning of Bayesian Networks by Genetic Algorithms》阅读笔记</a>
                </li>
    </ul>
                </li>
    </ul>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="#">Python</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../python/SPHINX%20%E4%BD%BF%E7%94%A8/">SPHINX 使用</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/argmax%EF%BC%8Cargsort%E7%9A%84%E4%BD%BF%E7%94%A8/">argmax，argsort的使用</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/conda%20%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83/">conda 虚拟环境</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/datatime%20%E6%A8%A1%E5%9D%97/">datetime 模块</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/django/">django</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/flask%20%E5%B0%8F%E5%9E%8B%E5%8D%9A%E5%AE%A2/">flask 小型博客</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/google%20%E6%96%87%E6%A1%A3%E6%A0%87%E5%87%86/">Google 文档标准</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/keras.backend.rnn%E5%AD%A6%E4%B9%A0/">keras.backend.rnn学习</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/lru_cache%20%E8%A3%85%E9%A5%B0%E5%99%A8/">lru_cache 装饰器</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/np.cov%20%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5%E7%9A%84%E8%AE%A1%E7%AE%97/">np.cov 协方差矩阵的计算</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/python%20logging%20%E6%A0%87%E5%87%86%E5%BA%93/">python logging 标准库</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/python%20%E7%B1%BB%E4%B8%8E%E5%AF%B9%E8%B1%A1/">Python 类与对象</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/python%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">Python学习笔记</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/pytorch%20%E5%AD%A6%E4%B9%A0/">pytorch 学习</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/super%28%29/">super()</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/tkinter%20%E5%AD%A6%E4%B9%A0/">tkinter 学习</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/try%E7%9A%84%E7%94%A8%E6%B3%95/">try的用法</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/%E3%80%8Acelery%E3%80%8B/">《celery》</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0/">内置函数</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/%E5%AE%9A%E4%B9%89%E5%87%BD%E6%95%B0/">定义函数</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/%E6%A8%A1%E5%9D%97/">模块</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/%E6%A8%A1%E5%9D%97%E4%B8%8E%E5%8C%85/">模块与包</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/%E7%94%9F%E6%88%90%E5%99%A8/">生成器</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/%E7%B1%BB/">类</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/%E8%A3%85%E9%A5%B0%E5%99%A8/">装饰器</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/%E9%97%AD%E5%8C%85/">闭包</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="#">Session 与 cookie.assets</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../python/session%20%E4%B8%8E%20cookie.assets/session%20%E4%B8%8E%20cookie/">session 与 cookie</a>
                </li>
    </ul>
                </li>
    </ul>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="#">书籍阅读</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB/%E3%80%8A%E5%87%B8%E4%BC%98%E5%8C%96%E3%80%8B/">凸优化学习笔记</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB/%E3%80%8A%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E3%80%8B/">《操作系统》</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB/%E3%80%8A%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%EF%BC%9A%E5%8E%9F%E7%90%86%E5%85%A5%E9%97%A8%E3%80%8B/">《深入浅出强化学习：原理入门》</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB/%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%8B/">深度学习</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB/%E3%80%8A%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">《算法导论》阅读笔记</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB/%E3%80%8A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">《计算机网络》读书笔记</a>
                </li>
    </ul>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="#">其他</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/JavaScript/">JavaScript</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/Jekyll%20%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/">Jekyll 搭建博客</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/Nginx/">Nginx教程</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/R%E8%AF%AD%E8%A8%80%E5%AD%A6%E4%B9%A0/">R语言学习</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/bootstrap%E5%AD%A6%E4%B9%A0/">bootstrap学习</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/docker/">docker</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/git%20%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/">git 版本控制</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/git/">git</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/htmlCSS/">html学习</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/http%E5%8D%8F%E8%AE%AE%E5%AD%A6%E4%B9%A0/">HTTP协议的学习</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/mysql%20%E5%AE%89%E8%A3%85/">mysql 安装</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/yum/">yum</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/%E3%80%8Adocker%E3%80%8B/">《docker》</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/%E4%BD%BF%E7%94%A8markdown%E5%88%B6%E4%BD%9Cppt/">slide 1</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/%E5%8A%9B%E6%89%A3%E9%A2%98%E7%9B%AE%E6%80%BB%E7%BB%93/">力扣题目总结</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/%E5%8F%82%E6%95%B0%E7%9A%84%E4%BC%A0%E9%80%92/">参数的传递</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/">强化学习</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/%E6%96%87%E4%BB%B6%E7%9A%84io/">文件的io</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/">线性代数</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/%E7%BA%BF%E7%A8%8B%E4%B8%8E%E8%BF%9B%E7%A8%8B/">线程与进程</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%E2%80%94%E2%80%94%E5%88%9D%E8%AF%86/">网络协议——初识</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/%E7%BD%91%E9%A1%B5%E7%9A%84%E7%BB%84%E6%88%90/">网页的组成</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/%E8%8D%89%E7%A8%BF%E6%9C%AC/">Draft</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/">计算机网络</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/">设计模式</a>
                </li>
    </ul>
                    </li>
                </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../../..">Huang Hao's Blog</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../..">Docs</a> &raquo;</li>
    
      
        
          <li>内容 &raquo;</li>
        
      
        
          <li>Paper阅读 &raquo;</li>
        
      
    
    <li>《The max-min hill-climbing Bayesian network structure learning algorithm》阅读笔记</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  
  <hr/>
</div>

          <div role="main">
            <div class="section">
              
                <h1 id="the-max-min-hill-climbing-bayesian-network-structure-learning-algorithm">《The max-min hill-climbing Bayesian network structure learning algorithm》阅读笔记</h1>
<p><img alt="image-20211220144004427" src="../%E3%80%8AThe%20max-min%20hill-climbing%20Bayesian%20network%20structure%20learning%20algorithm%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0.assets/image-20211220144004427.png" /></p>
<p>引用了1724次的混合型贝叶斯网络结构学习算法。</p>
<p><img alt="https://healthinformatics-d8.dev.umn.edu/" src="../%E3%80%8AThe%20max-min%20hill-climbing%20Bayesian%20network%20structure%20learning%20algorithm%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0.assets/aliferis_0-web.jpg" /></p>
<h2 id="abstract">abstract</h2>
<p>MMHC算法融合了local learning， constraint based， search and score techniques。首先算法重建出BN的骨架，然后用爬山算法来确定边的方向。</p>
<h2 id="introduction">introduction</h2>
<p>贝叶斯网络用于代表一个联合概率分布。</p>
<p>贝叶斯网络结构学习被广泛使用，网络结构的边具有因果语义。引用文献</p>
<p><img alt="image-20211220144946452" src="../%E3%80%8AThe%20max-min%20hill-climbing%20Bayesian%20network%20structure%20learning%20algorithm%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0.assets/image-20211220144946452.png" /></p>
<p>卡耐基梅隆大学的哲学与人文社科系。</p>
<p><img src="《The max-min hill-climbing Bayesian network structure learning algorithm》阅读笔记.assets/image-20211220145216493.png" alt="image-20211220145216493" style="zoom:50%;" /></p>
<hr />
<p>目前贝叶斯网络结构学习无法 reliably scale up to thousands of variables in reasonable time。</p>
<p>本文提出MMHC，他能克服感知局限性。该算法能扩展到数千个变量。</p>
<p>结构学习方法有评分搜索算法。</p>
<p>结构学习方法有基于约束的算法。</p>
<p>介绍MMHC算法：首先学习骨架，使用max min parents and children；第二部使用贪婪的贝叶斯爬山搜索来确定骨架的方向。</p>
<p>MMHC算法可以视为Sparse Candidate algorithm 的一个实例。SC算法是第一个可以处理几百个变量的学习算法。SC算法首先，启发式地为每个变量估计一个candidate parent set，然后使用爬山算法来最大化评分。然后重新为每个变量估计candidate parent set，再次使用爬山算法来最大化评分。candidate set re estimate 接着 hill climb就是一次迭代过程。Sparese candidate 迭代，直到候选集没有变化，或者其他终止条件满足。</p>
<p>SC算法存在三个主要问题：</p>
<ol>
<li>candidate parents不可靠</li>
<li>需要指定最大的入度k</li>
<li>参数k是一种一致性的稀疏约束</li>
</ol>
<p>MMHC alleviates three problems above:</p>
<ol>
<li>remove super parameter k</li>
<li>only one iteration can gurantee the accuracy of candidate set</li>
</ol>
<hr />
<h2 id="background">background</h2>
<p>定义一：</p>
<p><img alt="image-20211220204305128" src="../%E3%80%8AThe%20max-min%20hill-climbing%20Bayesian%20network%20structure%20learning%20algorithm%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0.assets/image-20211220204305128.png" /></p>
<p>定义二：</p>
<p><img alt="image-20211220204348624" src="../%E3%80%8AThe%20max-min%20hill-climbing%20Bayesian%20network%20structure%20learning%20algorithm%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0.assets/image-20211220204348624.png" /></p>
<p>定义三、四、五都是关于d-separation的</p>
<p>Verma和 Pearl 证明了：</p>
<p><img alt="image-20211220204602487" src="../%E3%80%8AThe%20max-min%20hill-climbing%20Bayesian%20network%20structure%20learning%20algorithm%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0.assets/image-20211220204602487.png" /></p>
<p>定义六：</p>
<p>a distribution is faithful</p>
<p>定义七：</p>
<p>a faithful Bayesian network</p>
<hr />
<p>定理一：</p>
<p><img alt="image-20211220204909872" src="../%E3%80%8AThe%20max-min%20hill-climbing%20Bayesian%20network%20structure%20learning%20algorithm%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0.assets/image-20211220204909872.png" /></p>
<p>faithfulness 是本文的基本假设，用d-seperation 与 条件独立 连接起来。</p>
<p>定理二：</p>
<p><img alt="image-20211220205154196" src="../%E3%80%8AThe%20max-min%20hill-climbing%20Bayesian%20network%20structure%20learning%20algorithm%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0.assets/image-20211220205154196.png" /></p>
<h2 id="the-max-min-parents-and-children-algorithm-mmpc">the max min parents and children algorithm （MMPC算法）</h2>
<p>使用MMPC算法来得到一个 假阳性的结构：</p>
<p><img alt="image-20211220202545471" src="../%E3%80%8AThe%20max-min%20hill-climbing%20Bayesian%20network%20structure%20learning%20algorithm%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0.assets/image-20211220202545471.png" /></p>
<p>在算法中可能会使用到两个函数</p>
<p>$\operatorname{Ind}(X ; T \mid \mathbf{Z})$</p>
<p>$\operatorname{Assoc}(X ; T \mid \mathbf{Z})$</p>
<p>分别用来评价条件独立与依赖关系，这是可以自定义的，在后续章节中也有详细描述。</p>
<p>定义 $\operatorname{MinAssoc}(X ; T \mid \mathbf{Z})$为：</p>
<p>通过改变<strong>S</strong>（<strong>S</strong>是<strong>Z</strong>的子集），使得association最小：</p>
<p><img alt="image-20211220155441742" src="../%E3%80%8AThe%20max-min%20hill-climbing%20Bayesian%20network%20structure%20learning%20algorithm%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0.assets/image-20211220155441742.png" /></p>
<p><img alt="image-20211220155306079" src="../%E3%80%8AThe%20max-min%20hill-climbing%20Bayesian%20network%20structure%20learning%20algorithm%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0.assets/image-20211220155306079.png" /></p>
<p>几个点需要注意：</p>
<p>因为：$\mathbf{S}<em>{1} \subseteq \mathbf{S}</em>{2} \Rightarrow \operatorname{Min} \operatorname{Assoc}\left(X ; Y \mid \mathbf{S}<em>{1}\right) \geq \operatorname{Min} \operatorname{Assoc}\left(X ; Y \mid \mathbf{S}</em>{2}\right)$，所以：随着CPC的增加，MinAssoc只会不变或者减小。如果某个变量与T的association为0，它不应该被加入到CPC，并且之后不再考虑，以保证：<strong>随着CPC的增加，the min association 减小</strong>。</p>
<h3 id="_1">案例：</h3>
<p>对于节点T, 数据D，数据是从该网络生成的：</p>
<p><img alt="image-20211220160831567" src="../%E3%80%8AThe%20max-min%20hill-climbing%20Bayesian%20network%20structure%20learning%20algorithm%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0.assets/image-20211220160831567.png" /></p>
<p>节点输入为T，进入到MMPC算法的Forward环节中去：</p>
<p><img alt="image-20211220161145610" src="../%E3%80%8AThe%20max-min%20hill-climbing%20Bayesian%20network%20structure%20learning%20algorithm%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0.assets/image-20211220161145610.png" /></p>
<p>第一次迭代，CPC是$\varnothing$ </p>
<p><img alt="image-20211220212308457" src="../%E3%80%8AThe%20max-min%20hill-climbing%20Bayesian%20network%20structure%20learning%20algorithm%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0.assets/image-20211220212308457.png" /></p>
<p>在MaxMinHeuristic中，不断地改变X，计算MinAssoc，发现X=A的时候，MinAssoc最大。在此时因为CPC是$\varnothing$ ，所以就是A与T的相关系数最大，同时计算到B, E的相关系数为0, 标记下来，不再考虑。</p>
<p><img alt="image-20211220165755352" src="../%E3%80%8AThe%20max-min%20hill-climbing%20Bayesian%20network%20structure%20learning%20algorithm%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0.assets/image-20211220165755352.png" /></p>
<p>继续，慢慢增加CPC集合</p>
<p><img alt="image-20211220165847525" src="../%E3%80%8AThe%20max-min%20hill-climbing%20Bayesian%20network%20structure%20learning%20algorithm%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0.assets/image-20211220165847525.png" /></p>
<p>继续增加CPC，同时因为A,D进入了CPC，由于A,D 的条件，会导致H,T的独立，继而删除 H, J</p>
<p><img alt="image-20211220165902902" src="../%E3%80%8AThe%20max-min%20hill-climbing%20Bayesian%20network%20structure%20learning%20algorithm%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0.assets/image-20211220165902902.png" /></p>
<p><img alt="image-20211220170020644" src="../%E3%80%8AThe%20max-min%20hill-climbing%20Bayesian%20network%20structure%20learning%20algorithm%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0.assets/image-20211220170020644.png" /></p>
<p>第二阶段：进入到 backward 过程，</p>
<p><img alt="image-20211220212857968" src="../%E3%80%8AThe%20max-min%20hill-climbing%20Bayesian%20network%20structure%20learning%20algorithm%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0.assets/image-20211220212857968.png" /></p>
<p>这个"存在 $\exists$"标记，代表着一种permutation。</p>
<p><img alt="image-20211220171330962" src="../%E3%80%8AThe%20max-min%20hill-climbing%20Bayesian%20network%20structure%20learning%20algorithm%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0.assets/image-20211220171330962.png" /></p>
<p>当permutation到 {C,D}时候，发现A,T独立，所以要删除A，最终输出 Parents and children 为 C、D、I 与事实相符合。</p>
<p>3.3 MMPC 算法修正</p>
<p>某个特殊情况下，前面描述的算法会出现假阳性：</p>
<p><img alt="image-20211220214208640" src="../%E3%80%8AThe%20max-min%20hill-climbing%20Bayesian%20network%20structure%20learning%20algorithm%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0.assets/image-20211220214208640.png" /></p>
<p>这样的结构下，前面描述的算法会输出PC={A, B, C}</p>
<p><img alt="image-20211220215118368" src="../%E3%80%8AThe%20max-min%20hill-climbing%20Bayesian%20network%20structure%20learning%20algorithm%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0.assets/image-20211220215118368.png" /></p>
<p>进行一次修正，再一次修改CPC</p>
<h2 id="tests-of-conditional-independence-and-measures-of-association">Tests of conditional independence and measures of association</h2>
<p>对于$\operatorname{Ind}\left(X_{i} ; X_{j} \mid \mathbf{X}_{k}\right)$：</p>
<p>计算统计量 $G^2$ , 类似于卡方检验</p>
<p><img alt="image-20211220215409340" src="../%E3%80%8AThe%20max-min%20hill-climbing%20Bayesian%20network%20structure%20learning%20algorithm%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0.assets/image-20211220215409340.png" /></p>
<p>g检验返回一个p-value，如果小于阈值则拒绝原假设。</p>
<h2 id="mmhc">MMHC</h2>
<p><img alt="image-20211220215838216" src="../%E3%80%8AThe%20max-min%20hill-climbing%20Bayesian%20network%20structure%20learning%20algorithm%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0.assets/image-20211220215838216.png" /></p>
<h2 id="optimizing-the-computational-performance">optimizing the computational performance</h2>
<p>略</p>
<h2 id="empirical-evaluation">empirical evaluation</h2>
<p>实验设计：</p>
<p><strong>选择比较算法</strong></p>
<ol>
<li>SC算法</li>
<li>PC</li>
<li>GHC</li>
<li>GES</li>
<li>MMHC</li>
</ol>
<p>在具体实现方面，遵循以下协议：</p>
<p>（1）更喜欢作者的实现，只要可用，只要它满足我们的实验需求，即可以在我们的实验平台上运行，对输入没有可变大小限制，并输出评估所需的最少一组统计数据。
（2） 如果不满足上述条件，将使用满足这些条件的算法的最佳公开实现。
（3） 否则，将重新实现该算法并使用我们的版本。</p>
<p><strong>选择公共数据集，网络</strong></p>
<ol>
<li>
<p>数据集描述</p>
</li>
<li>
<p>数据描述</p>
</li>
<li>
<p>评价指标</p>
</li>
<li>
<p>时间</p>
</li>
<li>statistical call</li>
<li>评分</li>
<li>SHD</li>
<li>同时比较时间与质量</li>
</ol>
<p><img alt="image-20211220221134155" src="../%E3%80%8AThe%20max-min%20hill-climbing%20Bayesian%20network%20structure%20learning%20algorithm%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0.assets/image-20211220221134155.png" /></p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../%E3%80%8Aattention%20is%20all%20your%20need%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" class="btn btn-neutral float-right" title="《attention is all your need》阅读笔记">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../%E3%80%8APC%20algorithm%E3%80%8B%E5%AD%A6%E4%B9%A0/" class="btn btn-neutral" title="《PC algorithm》学习"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../%E3%80%8APC%20algorithm%E3%80%8B%E5%AD%A6%E4%B9%A0/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../%E3%80%8Aattention%20is%20all%20your%20need%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script>var base_url = '../../..';</script>
    <script src="../../../js/theme_extra.js" defer></script>
    <script src="../../../js/theme.js" defer></script>
      <script src="../../../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
