<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  
  <link rel="shortcut icon" href="../../../img/favicon.ico">
  <title>《CAUSAL DISCOVERY WITH REINFORCEMENT LEARNING》 读书笔记 - Huang Hao's Blog</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700" />

  <link rel="stylesheet" href="../../../css/theme.css" />
  <link rel="stylesheet" href="../../../css/theme_extra.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
  
  <script>
    // Current page data
    var mkdocs_page_name = "\u300aCAUSAL DISCOVERY WITH REINFORCEMENT LEARNING\u300b \u8bfb\u4e66\u7b14\u8bb0";
    var mkdocs_page_input_path = "\u5185\u5bb9\\paper\u9605\u8bfb\\\u300aCAUSAL DISCOVERY WITH REINFORCEMENT LEARNING\u300b \u8bfb\u4e66\u7b14\u8bb0.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../../../js/jquery-2.1.1.min.js" defer></script>
  <script src="../../../js/modernizr-2.8.3.min.js" defer></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
        <a href="../../.." class="icon icon-home"> Huang Hao's Blog</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../..">Huang Hao' Blog</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">内容</span></p>
                <ul class="current">
                    <li class="toctree-l1 current"><a class="reference internal current" href="#">Paper阅读</a>
    <ul class="current">
                <li class="toctree-l2"><a class="reference internal" href="../Bayesian%20network%20structure%20learning%20%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E9%97%AE%E9%A2%98/">Bayesian network structure learning: 最短路径问题</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../EM%20algorithm%20%E6%9C%9F%E6%9C%9B%E6%9C%80%E5%A4%A7%E7%AE%97%E6%B3%95/">EM algorithm 期望最大算法</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../K2%E7%AE%97%E6%B3%95%E3%80%8AA%20Bayesian%20Method%20for%20the%20Induction%20of%20Probabilistic%20Networks%20from%20Data%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">K2算法《A Bayesian Method for the Induction of Probabilistic Networks from Data》阅读笔记</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../Linear%20non-Gaussian%20Acyclic%20Model/">A Linear Non-Gaussian Acyclic Model for Causal Discovery</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../%E3%80%8AA%20Survey%20of%20Learning%20Causality%20with%20Data%20Problems%20and%20Methods%E3%80%8B/">《A Survey of Learning Causality with Data: Problems and Methods》阅读笔记</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../%E3%80%8AAtomistic%20Line%20Graph%20Neural%20Network%20for%20improved%20materials%20property%20predictions%E3%80%8B%20%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">《Atomistic Line Graph Neural Network for improved materials property predictions》 阅读笔记</a>
                </li>
                <li class="toctree-l2 current"><a class="reference internal current" href="./">《CAUSAL DISCOVERY WITH REINFORCEMENT LEARNING》 读书笔记</a>
    <ul class="current">
    <li class="toctree-l3"><a class="reference internal" href="#abstract">abstract</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#intro">intro</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#related-work">related work</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#model-definition">model definition</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#neural-network-architecture-for-graph-generation">Neural network architecture for graph generation</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#encoder">encoder</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#decoder">decoder</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#reinforcement-learning-for-search">Reinforcement learning for search</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#score-function-acyclicity-reward">score function, acyclicity, reward</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#actor-critic-algorithm">actor-critic algorithm</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#_1">算法详细：</a>
    </li>
        </ul>
    </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../%E3%80%8AExploiting%20Experts%E2%80%99%20Knowledge%20for%20Structure%20Learning%20of%20Bayesian%20Networks%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">《Exploiting Experts’ Knowledge for Structure Learning of Bayesian Networks》阅读笔记</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../%E3%80%8AImproved%20K2%20algorithm%20for%20Bayesian%20network%20structure%20learning%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">《Improved K2 algorithm for Bayesian network structure learning》阅读笔记</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../%E3%80%8ALearning%20to%20Optimize%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">《Learning to Optimize》阅读笔记</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../%E3%80%8ANEURAL%20COMBINATORIAL%20OPTIMIZATION%20WITH%20REINFORCEMENT%20LEARNING%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">《NEURAL COMBINATORIAL OPTIMIZATION WITH REINFORCEMENT LEARNING》读书笔记</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../%E3%80%8ANeural%20Machine%20Translation%20By%20Jointly%20Learning%20To%20Align%20And%20Translate%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">《Neural Machine Translation By Jointly Learning To Align And Translate》阅读笔记</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../%E3%80%8APC%20algorithm%E3%80%8B%E5%AD%A6%E4%B9%A0/">《PC algorithm》学习</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../%E3%80%8AThe%20max-min%20hill-climbing%20Bayesian%20network%20structure%20learning%20algorithm%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">《The max-min hill-climbing Bayesian network structure learning algorithm》阅读笔记</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../%E3%80%8Aattention%20is%20all%20your%20need%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">《attention is all your need》阅读笔记</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../%E3%80%8Adetermining%20the%20direction%20of%20the%20local%20search%20in%20topological%20ordering%20space%20for%20Bayesian%20network%20structure%20learning%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94/">《determining the direction of the local search in topological ordering space for Bayesian network structure learning》阅读笔记</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../%E3%80%8AdirectLiGAM%E3%80%8B%E7%BB%93%E6%9E%84%E6%96%B9%E7%A8%8B%E6%A8%A1%E5%9E%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">《A Linear Non-Gaussian Acyclic Model for Causal Discovery》读书笔记</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../%E3%80%8Apointer%20networks%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">《pointer networks》阅读笔记</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90%EF%BC%9A%E4%B8%89%E6%AC%A1%E6%A0%B7%E6%9D%A1%E6%8F%92%E5%80%BC/">数值分析：三次样条插值</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../%E9%A2%91%E7%8E%87%E7%BB%9F%E8%AE%A1%E5%AD%A6VS%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BB%9F%E8%AE%A1%E5%AD%A6/">频率统计学VS贝叶斯统计学</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="#">《Neural Machine Translation By Jointly Learning To Align And Translate》阅读笔记.assets</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../%E3%80%8ANeural%20Machine%20Translation%20By%20Jointly%20Learning%20To%20Align%20And%20Translate%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0.assets/BIC%20%E8%AF%84%E5%88%86/">BIC 评分</a>
                </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="#">《PC algorithm》学习.assets</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../%E3%80%8APC%20algorithm%E3%80%8B%E5%AD%A6%E4%B9%A0.assets/%E3%80%8AStructure%20Learning%20of%20Bayesian%20Networks%20by%20Genetic%20Algorithms%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">《Structure Learning of Bayesian Networks by Genetic Algorithms》阅读笔记</a>
                </li>
    </ul>
                </li>
    </ul>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="#">Python</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../python/SPHINX%20%E4%BD%BF%E7%94%A8/">SPHINX 使用</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/argmax%EF%BC%8Cargsort%E7%9A%84%E4%BD%BF%E7%94%A8/">argmax，argsort的使用</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/conda%20%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83/">conda 虚拟环境</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/datatime%20%E6%A8%A1%E5%9D%97/">datetime 模块</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/django/">django</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/flask%20%E5%B0%8F%E5%9E%8B%E5%8D%9A%E5%AE%A2/">flask 小型博客</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/google%20%E6%96%87%E6%A1%A3%E6%A0%87%E5%87%86/">Google 文档标准</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/keras.backend.rnn%E5%AD%A6%E4%B9%A0/">keras.backend.rnn学习</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/lru_cache%20%E8%A3%85%E9%A5%B0%E5%99%A8/">lru_cache 装饰器</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/np.cov%20%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5%E7%9A%84%E8%AE%A1%E7%AE%97/">np.cov 协方差矩阵的计算</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/python%20logging%20%E6%A0%87%E5%87%86%E5%BA%93/">python logging 标准库</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/python%20%E7%B1%BB%E4%B8%8E%E5%AF%B9%E8%B1%A1/">Python 类与对象</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/python%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">Python学习笔记</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/pytorch%20%E5%AD%A6%E4%B9%A0/">pytorch 学习</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/super%28%29/">super()</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/tkinter%20%E5%AD%A6%E4%B9%A0/">tkinter 学习</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/try%E7%9A%84%E7%94%A8%E6%B3%95/">try的用法</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/%E3%80%8Acelery%E3%80%8B/">《celery》</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0/">内置函数</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/%E5%AE%9A%E4%B9%89%E5%87%BD%E6%95%B0/">定义函数</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/%E6%A8%A1%E5%9D%97/">模块</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/%E6%A8%A1%E5%9D%97%E4%B8%8E%E5%8C%85/">模块与包</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/%E7%94%9F%E6%88%90%E5%99%A8/">生成器</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/%E7%B1%BB/">类</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/%E8%A3%85%E9%A5%B0%E5%99%A8/">装饰器</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../python/%E9%97%AD%E5%8C%85/">闭包</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="#">Session 与 cookie.assets</a>
    <ul>
                <li class="toctree-l3"><a class="reference internal" href="../../python/session%20%E4%B8%8E%20cookie.assets/session%20%E4%B8%8E%20cookie/">session 与 cookie</a>
                </li>
    </ul>
                </li>
    </ul>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="#">书籍阅读</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB/%E3%80%8A%E5%87%B8%E4%BC%98%E5%8C%96%E3%80%8B/">凸优化学习笔记</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB/%E3%80%8A%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E3%80%8B/">《操作系统》</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB/%E3%80%8A%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%EF%BC%9A%E5%8E%9F%E7%90%86%E5%85%A5%E9%97%A8%E3%80%8B/">《深入浅出强化学习：原理入门》</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB/%E3%80%8A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%8B/">深度学习</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB/%E3%80%8A%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">《算法导论》阅读笔记</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB/%E3%80%8A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">《计算机网络》读书笔记</a>
                </li>
    </ul>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="#">其他</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/JavaScript/">JavaScript</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/Jekyll%20%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/">Jekyll 搭建博客</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/Nginx/">Nginx教程</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/R%E8%AF%AD%E8%A8%80%E5%AD%A6%E4%B9%A0/">R语言学习</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/bootstrap%E5%AD%A6%E4%B9%A0/">bootstrap学习</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/docker/">docker</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/git%20%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/">git 版本控制</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/git/">git</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/htmlCSS/">html学习</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/http%E5%8D%8F%E8%AE%AE%E5%AD%A6%E4%B9%A0/">HTTP协议的学习</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/mysql%20%E5%AE%89%E8%A3%85/">mysql 安装</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/yum/">yum</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/%E3%80%8Adocker%E3%80%8B/">《docker》</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/%E4%BD%BF%E7%94%A8markdown%E5%88%B6%E4%BD%9Cppt/">slide 1</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/%E5%8A%9B%E6%89%A3%E9%A2%98%E7%9B%AE%E6%80%BB%E7%BB%93/">力扣题目总结</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/%E5%8F%82%E6%95%B0%E7%9A%84%E4%BC%A0%E9%80%92/">参数的传递</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/">强化学习</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/%E6%96%87%E4%BB%B6%E7%9A%84io/">文件的io</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/">线性代数</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/%E7%BA%BF%E7%A8%8B%E4%B8%8E%E8%BF%9B%E7%A8%8B/">线程与进程</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%E2%80%94%E2%80%94%E5%88%9D%E8%AF%86/">网络协议——初识</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/%E7%BD%91%E9%A1%B5%E7%9A%84%E7%BB%84%E6%88%90/">网页的组成</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/%E8%8D%89%E7%A8%BF%E6%9C%AC/">Draft</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/">计算机网络</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../%E5%85%B6%E4%BB%96/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/">设计模式</a>
                </li>
    </ul>
                    </li>
                </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../../..">Huang Hao's Blog</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../..">Docs</a> &raquo;</li>
    
      
        
          <li>内容 &raquo;</li>
        
      
        
          <li>Paper阅读 &raquo;</li>
        
      
    
    <li>《CAUSAL DISCOVERY WITH REINFORCEMENT LEARNING》 读书笔记</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  
  <hr/>
</div>

          <div role="main">
            <div class="section">
              
                <h1 id="causal-discovery-with-reinforcement-learning">《CAUSAL DISCOVERY WITH REINFORCEMENT LEARNING》 读书笔记</h1>
<p>作者Shengyu Zhu华为诺亚实验室，发表在ICLR。</p>
<p>https://cn.linkedin.com/in/shengyuzhu </p>
<p>https://github.com/huawei-noah/trustworthyAI/tree/master/Causal_Structure_Learning/Causal_Discovery_RL</p>
<h2 id="abstract">abstract</h2>
<p>causal inference = causal effect + causal relationships（贝叶斯网络做的是因果关系发现）</p>
<p>因果发现。传统的因果发现基于的是local heuristics，依据 score function。</p>
<p>但是，greedy equivalence search 可能在无限的样本数目下，一定的模型假设情况下有不错的结果，它的表现在有限数据已经假设不满足的情况下表现欠佳。</p>
<p>基于neural combinatorial optimization的工作，提出RL 来搜索DAG。</p>
<p>encoder-decoder模型：输入数据，生成邻接矩阵，并计算reward。reward考虑了score function 和 两个惩罚项来保证无环性。</p>
<p>与传统的RL模型，为了得到policy。我们使用RL来得到一个search strategy，我们最终的结果是一个DAG。</p>
<p>synthetic data与real data同样适用。</p>
<h2 id="intro">intro</h2>
<p>问题：</p>
<p><img alt="image-20211022150316817" src="../%E3%80%8ACAUSAL%20DISCOVERY%20WITH%20REINFORCEMENT%20LEARNING%E3%80%8B%20%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0.assets/image-20211022150316817.png" /></p>
<p>其中$S()$已经被大量研究，例如：BIC, MDL, BGe.</p>
<p>这个问题是一个NP难问题。</p>
<p>常用local heuristic解决：Greedy Equivalence Search，MMHC。</p>
<p>最近：X. Zheng, B. Aragam, P. Ravikumar, and E. P. Xing. DAGs with NO TEARS: Continuous optimization for structure learning. In Advances in Neural Information Processing Systems, 2018. 将问题转化为连续优化问题。</p>
<p>随后还有人在此基础上做了改良：</p>
<p><img alt="image-20211022150825828" src="../%E3%80%8ACAUSAL%20DISCOVERY%20WITH%20REINFORCEMENT%20LEARNING%E3%80%8B%20%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0.assets/image-20211022150825828.png" /></p>
<p>本文提出：使用RL来搜索DAG。</p>
<ol>
<li>使用编码器-解码器输出一个 G</li>
<li>根据这个G计算reward，这个reward考虑了：‘得分’与‘无环性’。</li>
<li>使用policy gradient与随机优化策略来优化 ‘编码器-解码器’。</li>
</ol>
<p><img alt="image-20211022151326467" src="../%E3%80%8ACAUSAL%20DISCOVERY%20WITH%20REINFORCEMENT%20LEARNING%E3%80%8B%20%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0.assets/image-20211022151326467.png" /></p>
<h2 id="related-work">related work</h2>
<p>基于constraint-based 的因果推断方法，首先使用条件独立性检验来确定骨架，然后再决定方向。PC算法。</p>
<p>还有一类因果推断方法基于properly defined functional causal models。例如：</p>
<ul>
<li>LiNGAM</li>
<li>the nonlinear additive noise model</li>
<li>post-nonlinear causal model</li>
</ul>
<h2 id="model-definition">model definition</h2>
<p>$$
x_{i}:=f_{i}\left(\mathrm{x}<em>{\mathrm{pa}(i)}\right)+n</em>{i}, i=1,2, \ldots, d
$$</p>
<p>其中$\mathrm{x}<em>{\mathrm{pa}(i)}$是$x</em>{i}$的父节点（s），$f_{i}()$是一个固定的函数，$n_{i}$固定分布的噪音。</p>
<p>对于样本
$$
X_{n \times d}
$$
记为：
$$
\mathbf{x}:=\left{{x}<em>{i}\right}</em>{i=1}^{d}
$$</p>
<h2 id="neural-network-architecture-for-graph-generation">Neural network architecture for graph generation</h2>
<p>在数据中，随机抽取n个样本（可重复），$x^k$是第k个样本，共有n个样本。</p>
<p>所以数据为：
$$
{x^l}^n_{l=1}
$$
一共有n行，d列，所以记：
$$
s ={\tilde{x}}^d_{i=1}
$$
使用指针神经网络：</p>
<ol>
<li>随机抽取n个样本出来（with replacement），$\left{\mathrm{x}^{l}\right}_{l=1}^{n}$</li>
<li>得到$\mathbf{s}:=\left{\tilde{\mathbf{x}}<em>{i}\right}</em>{i=1}^{d}$ ，这里的$\tilde{\mathbf{x}}_{i}$，是一个变量的所有取值，就是原来x的一列。</li>
<li>$\tilde{\mathbf{x}}_{i} \in R^{1\times n}$, 类比于TSP问题，它是$d$ 个城市的 n-dim坐标。</li>
</ol>
<h3 id="encoder">encoder</h3>
<p>使用transformer模型。</p>
<p><img alt="image-20211123223642757" src="../%E3%80%8ACAUSAL%20DISCOVERY%20WITH%20REINFORCEMENT%20LEARNING%E3%80%8B%20%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0.assets/image-20211123223642757.png" /></p>
<p>过程：</p>
<p>观测数据 [n,d]  转置一下 [d,n]</p>
<p>进encoder（假设最后的feed forwad为），得到 [d,512]</p>
<p>encoder---&gt;   $enc_i,i=1,2,3...d$</p>
<h3 id="decoder">decoder</h3>
<p>以成对的方式考虑边的情况。building relationship between two $enc_i$, 所以decoder得到的结果：
$$
g_{i j}\left(W_{1}, W_{2}, u\right)=u^{T} \tanh \left(W_{1} \text { enc }<em>{i}+W</em>{2} \text { enc }_{j}\right)
$$</p>
<p>$$
[g_{0, 0},g_{0, 1},...,g_{0, j}],\
[g_{1, 0},g_{1, 1},...,g_{1, j}],\
...\
[g_{1, 0},g_{1, 1},...,g_{i, j}]
$$</p>
<h2 id="reinforcement-learning-for-search">Reinforcement learning for search</h2>
<p>使用RL作为搜索策略。</p>
<h3 id="score-function-acyclicity-reward">score function, acyclicity, reward</h3>
<p>评分函数：本文使用RL agent来最大化评分函数</p>
<p>BIC评分：
$$
\mathcal{S}<em>{\mathrm{BIC}}(\mathcal{G})=\sum</em>{i=1}^{d}\left(m \log \left(\mathrm{RSS}_{i} / m\right)\right)+#(\text { edges }) \log m
$$</p>
<p>$$
\mathcal{S}<em>{\mathrm{BIC}}(\mathcal{G})=m d \log \left(\left(\sum</em>{i=1}^{d} \operatorname{RSS}_{i}\right) /(m d)\right)+#(\text { edges }) \log m
$$</p>
<p>acyclicity：
$$
h(A):=\operatorname{trace}\left(e^{A}\right)-d=0
$$
reward：
$$
\text { reward := }-\left[\mathcal{S}(\mathcal{G})+\lambda_{1} \mathbf{I}(\mathcal{G} \notin \mathrm{DAGs})+\lambda_{2} h(A)\right]
$$
$I$是一个指示函数。</p>
<p>所以现在要处理的问题被改写为：
$$
\min <em>{\mathcal{G}}\left[\mathcal{S}(\mathcal{G})+\lambda</em>{1} \mathbf{I}(\mathcal{G} \notin \mathrm{DAGs})+\lambda_{2} h(A)\right]
$$
原问题是:
$$
\min _{\mathcal{G}} \mathcal{S}(\mathcal{G}), \text { subject to } \mathcal{G} \in \mathrm{DAGs}
$$
<strong>两个问题在什么情况下等价呢？</strong></p>
<p>因为h(A)的计算采用的是近似算法，所以并不能严格遵守h(A)=0。一般情况下h(A)&lt;$h_{min}$就认定A为无向图。</p>
<p>记：$h_{min}$ 是最小的有环图，$S^<em>$是原问题的最低分。$S_L$是松弛以后的下界，$S_U$是松弛以后的上界。（$S_L$&lt;=$S^</em>$&lt;=$S_U$）</p>
<p>两个问题等价，当：
$$
\lambda_{1}+\lambda_{2} h_{\min } \geq \mathcal{S}<em>{U}-\mathcal{S}</em>{L}
$$
证明：
$$
对于原问题来说：假设 G 是一个解，那么 S^<em> = S(G) \
如果说G 不是"改写问题" 的解，那么存在一个 G（可能有向）\
\mathcal{S}^{</em>}&gt;\mathcal{S}\left(\mathcal{G}^{\prime}\right)+\lambda_{1} \mathbf{I}\left(\mathcal{G}^{\prime} \notin \text { DAGs }\right)+\lambda_{2} h\left(A^{\prime}\right)\
很明显，\mathcal{G}^{\prime}不是一个DAG，\
\mathcal{S}\left(\mathcal{G}^{\prime}\right)+\lambda_{1} \mathbf{I}\left(\mathcal{G}^{\prime} \notin \text { DAGs }\right)+\lambda_{2} h\left(A^{\prime}\right)&gt;S_L+\lambda_{1}+\lambda_{2} h_{\min }&gt;=S_U
$$</p>
<h3 id="actor-critic-algorithm">actor-critic algorithm</h3>
<p><img alt="image-20211124145839097" src="../%E3%80%8ACAUSAL%20DISCOVERY%20WITH%20REINFORCEMENT%20LEARNING%E3%80%8B%20%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0.assets/image-20211124145839097.png" /></p>
<p>policy：
$$
\pi(\cdot \mid \mathrm{s})
$$
NN（编码器，解码器）的参数：
$$
\psi
$$
训练的目标，期望奖励为：
$$
J(\psi \mid \mathbf{s})=\mathbb{E}<em>{A \sim \pi(\cdot \mid \mathrm{s})}\left{-\left[\mathcal{S}(\mathcal{G})+\lambda</em>{1} \mathbf{I}(\mathcal{G} \notin \mathrm{DAGs})+\lambda_{2} h(A)\right]\right}
$$</p>
<h3 id="_1">算法详细：</h3>
<p>data 先进入 encoder，得到 encs</p>
<p>encs进入critic，得到预测到的reward</p>
<p>encs和预测reward进入到decoder，得到图，图再使用准确计算，得到真实reward</p>
<p>真实的reward-预测的reward，得到loss，使用这个loss来更新critc</p>
<p>然后使用更新后的critc预测的reward，encs进入到decoder，使用这个loss来更新actor</p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../%E3%80%8AExploiting%20Experts%E2%80%99%20Knowledge%20for%20Structure%20Learning%20of%20Bayesian%20Networks%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" class="btn btn-neutral float-right" title="《Exploiting Experts’ Knowledge for Structure Learning of Bayesian Networks》阅读笔记">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../%E3%80%8AAtomistic%20Line%20Graph%20Neural%20Network%20for%20improved%20materials%20property%20predictions%E3%80%8B%20%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" class="btn btn-neutral" title="《Atomistic Line Graph Neural Network for improved materials property predictions》 阅读笔记"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../%E3%80%8AAtomistic%20Line%20Graph%20Neural%20Network%20for%20improved%20materials%20property%20predictions%E3%80%8B%20%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../%E3%80%8AExploiting%20Experts%E2%80%99%20Knowledge%20for%20Structure%20Learning%20of%20Bayesian%20Networks%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script>var base_url = '../../..';</script>
    <script src="../../../js/theme_extra.js" defer></script>
    <script src="../../../js/theme.js" defer></script>
      <script src="../../../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
