# 《线性代数及其应用》

线性代数是一个“**折腾**”矩阵、方程的科学，以这种方式来挖掘关于方程的“**信息**”。

线性代数可以理解为一种特征工程，各种各样的特征导致这本书**概念**偏多。

此次笔记是为了**快速回顾**线性代数的基本概念以及**知识应用**场景。

## 目录

总览、复习相关的重要概念：

1. 线性方程组
   1. 系数矩阵
   2. 增广矩阵
   3. 阶梯形矩阵
   4. 简化阶梯形
   5. 主元
   6. 基本变量、自由变量
2. 矩阵的逆
3. 维数与秩
4. 向量
5. 特征值与特征向量

## 线性方程组

![image-20220322111941043](%E3%80%8A%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8%E3%80%8B.assets/image-20220322111941043.png)

用矩阵来展示线性方程组的信息，这样的矩阵有：

1. 系数矩阵
2. 增广矩阵

![image-20220322112009597](%E3%80%8A%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8%E3%80%8B.assets/image-20220322112009597.png)

![image-20220322111955074](%E3%80%8A%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8%E3%80%8B.assets/image-20220322111955074.png)

为了解线性方程，我们常用**行化简算法**，在此，将这种操作方式一般化，可以得到概念：

1. 阶梯形矩阵
2. 简化阶梯形
3. 主元
4. 基本变量、自由变量

## 向量方程

向量在深度学习领域经常应用，本质上它也是一种矩阵。

向量：仅有一列的矩阵。

定义：

![image-20220322112919284](%E3%80%8A%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8%E3%80%8B.assets/image-20220322112919284.png)

向量的运算：

![image-20220322113014294](%E3%80%8A%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8%E3%80%8B.assets/image-20220322113014294.png)

通过向量，可以将之前的线性方程组写为：

![image-20220322113157352](%E3%80%8A%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8%E3%80%8B.assets/image-20220322113157352.png)

这样的话，线性方程变得更加简洁：
$$
A = [a_1,a_2,...,a_n]\\
x = [x_1,x_2,...,x_n]^T\\
b = [b_1,b_2,...,b_n]^T\\
Ax=b
$$
对于向量方程来说，有以下概念：

1. 向量
2. 标量
3. 向量的加法（平行四边形法则）
4. 线性组合
5. $span(v_1,v_2,...,v_n)$ 是向量张成的集合
6. 线性无关

## 线性变换

对于
$$
Ax=b
$$
这个方程的研究不仅仅拘泥于线性方程组，他可以衍生到各种领域。在此将这个方程理解为：

将$A$通过乘法施加到向量$x$上，得到向量$b$，可以称之为线性变换。

![image-20220322115028221](%E3%80%8A%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8%E3%80%8B.assets/image-20220322115028221.png)

## 矩阵代数

$$
Ax=b\\
Bb=B(Ax)=BAx
$$

如果对$x$施加两次线性变换，那么将得到BA，这两次线性变换的叠加该如何处理呢？所以需要对矩阵代数开始定义。

1. 标量乘法
2. 矩阵乘法
3. 矩阵的乘幂
4. 矩阵的转置
5. 矩阵的逆

## 可逆矩阵

如果一个矩阵可逆，那么它具有非常多有价值的“信息”。

![image-20220322120400498](%E3%80%8A%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8%E3%80%8B.assets/image-20220322120400498.png)

求逆矩阵

![image-20220322120641527](%E3%80%8A%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8%E3%80%8B.assets/image-20220322120641527.png)

> 对于计算机来说，由于计算的舍入误差，会导致行变换的过程中产生小于n个主元位置，导致矩阵不可逆。同时也可能让奇异矩阵变得可逆。为了避免这种情况，要计算矩阵的条件数，条件数太大则说明计算可能发生错误。

## 矩阵的因式分解

$$
A=BC
$$



有时候为了更好地理解某一种“作用”, 需要把矩阵进行分解。

1. LU分解

暂时不详细了解。

## 特征向量与特征值

$$
Ax=b
$$

对于这样的作用，我们如何**分析A**以“预测”作用后的结果呢？

**特征值**

![image-20220322123709603](%E3%80%8A%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8%E3%80%8B.assets/image-20220322123709603.png)
$$
Ax = \lambda x
$$
A发挥的作用仅仅是拉伸x，所以说$\lambda$是A的特征值，x是特征向量

对于A来说，如果我们能找到它的特征值。

