# 探索“贝叶斯优化”

原文来自Distill社区，[《Exploring Bayesian Optimization》](https://distill.pub/2020/bayesian-optimization/)

贝叶斯优化与其他优化算法一样，都是最大化或者最小化某个函数。相比起其他算法，贝叶斯优化适用于任何**未知函数**。

## 引子

假设我们要优化f(x)，它的形状如图：

![image-20220504132422117](%E6%8E%A2%E7%B4%A2%E2%80%9C%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96%E2%80%9D.assets/image-20220504132422117.png)

有两个常见的目标：

1. 主动学习：估计出f(x)形状；
2. 贝叶斯优化：找到最有可能是最高点的x。

## 主动学习

因为昂贵的计算成本，我们只能计算几次f(x)，所以需要一个代理模型来代表未被计算过的地方f(x)的取值。常用的代理模型有高斯过程，在这里使用它。

通过计算f(x)，可以更新代理模型，如图所示：

![image-20220504133037012](%E6%8E%A2%E7%B4%A2%E2%80%9C%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96%E2%80%9D.assets/image-20220504133037012.png)

最开始代理模型是一个平滑分布的GP，通过一次探索（红点），代理模型根据贝叶斯规则得到了更新。

在这样的更新过程中，有这样的问题：为了尽可能地减少探索次数，我们该如何选择探索点？选择不确定度最高的点进行探索。

如图描述了探索的过程，代理模型的随机性在一次次的探索过程中随机性不断降低。

![image-20220504133915384](%E6%8E%A2%E7%B4%A2%E2%80%9C%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96%E2%80%9D.assets/image-20220504133915384.png)

## 贝叶斯优化

主动学习，通过探索具体的位置来不断更新代理模型，最终我们可以得到关于f(x)的估计。但是存在浪费，我们的目标是寻找最大值，但是我们探索了“低谷”。

贝叶斯优化尝试回答这样的问题：基于目前已知的，那个点是我们接下来应该探索的呢? 

> 这非常重要，因为探索是非常昂贵的，费时的。

做决定的东西被称为：acquisition function，acquisition function启发式地决定下一次探索的点，基于当前模型。

## 贝叶斯优化算法

1. 选择代理模型（surrogate model），e.g. 高斯过程模型；
2. 计算某一点的f(x)，根据（x,f(x)）来更新代理模型；
3. 使用采集函数（acquisition function）决定下一次的探索点；
4. 重复2-3，直到收敛或者满足终止条件。

> 特点：
>
> 1. 免梯度。
> 2. f(x)完全黑箱，甚至可以是一个化学反应。
> 3. 考虑了不确定性。

## 采集函数

采集函数对贝叶斯优化非常重要，有多种选择，在此介绍PI采集函数（Probability of improvement）。
$$
x_{t+1}=argmax(\alpha(x))=argmax(P(f(x)>f(x^++\epsilon)))
$$
其中$f(x^+)$是当前查询到的最大值。

如果说代理模型是GP，那么上面的式子可以写为：
$$
x_{t+1}=\underset{x}{\operatorname{argmax}} \phi(\frac{u_t(x-f(x^+)-\epsilon)}{\sigma_t(x)})
$$
还有很多其他的采集函数，针对不同的代理模型，可能会有对应的简化计算。对于上面的f(x)函数，不同采集函数的采集过程如图所示：

![comp](%E6%8E%A2%E7%B4%A2%E2%80%9C%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96%E2%80%9D.assets/comp.svg)

可以看出采集函数型比起Random具有一定的指导意义，UCB,EI函数的速度较快。

## Links：

一些贝叶斯优化的开源库：

- [scikit-optimize](https://scikit-optimize.github.io/) 
- [sigopt](https://app.sigopt.com/docs/overview/python)
- [hyperopt](http://hyperopt.github.io/hyperopt/)
- [spearmint](https://github.com/HIPS/Spearmint)
- [MOE](https://github.com/Yelp/MOE)
- [BOTorch](https://botorch.org/tutorials/)
- [GPyOpt](https://github.com/SheffieldML/GPyOpt)
- [DragonFly](https://github.com/dragonfly/dragonfly)